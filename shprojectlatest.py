# -*- coding: utf-8 -*-
"""SHProjectLatest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qLne4Do6KRotFrC3Vf_DijXD9jJwDGDr
"""

from google.colab import files

# Prompt user to upload required files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import time

from datetime import datetime, timedelta

# Correct session date for each participant
session_dates = {
    'participant1': '2024-08-21',
    'participant2': '2024-08-29',
    'participant3': '2024-09-21'
}

# Participant label and HRV mapping
participants = {
    'participant1': ('updated_968050_FrontView_Labels.xlsx', 'mock_1-1-MOODSTUDY_2024-08-21_prv.csv'),
    'participant2': ('updated_968046_FrontView_Labels.xlsx', 'updated_1-1-MOODSTUDY_2024-08-29_prv.csv'),
    'participant3': ('updated_968048_FrontView_Labels.xlsx', 'updated_1-1-MOODSTUDY_2024-09-21_prv.csv')
}

padding = timedelta(minutes=2)

def extract_segment(df, start, end, clip_name):
    padded_start = start - padding
    padded_end = end + padding
    segment = df[(df['timestamp_iso'] >= padded_start) & (df['timestamp_iso'] <= padded_end)].copy()
    segment['clip'] = clip_name
    return segment



all_segments = []

for pid, (label_file, hrv_file) in participants.items():
    print(f"\nğŸ” Processing {pid}")

    try:
        labels_df = pd.read_excel(label_file)
        hrv_df = pd.read_csv(hrv_file, parse_dates=['timestamp_iso'])
        print(f"âœ… Loaded: {label_file}, {hrv_file}")
    except Exception as e:
        print(f"âŒ Failed to load {pid}: {e}")
        continue

    # Timestamp conversion
    labels_df['start_time'] = pd.to_datetime(session_dates[pid]) + pd.to_timedelta('00:' + labels_df['music_starttime'])
    labels_df['end_time'] = pd.to_datetime(session_dates[pid]) + pd.to_timedelta('00:' + labels_df['music_endtime'])

    labels_df['start_time'] = labels_df['start_time'].dt.tz_localize('UTC')
    labels_df['end_time'] = labels_df['end_time'].dt.tz_localize('UTC')
    labels_df['type'] = labels_df['File_name'].apply(lambda x: 'Audio' if 'Audio' in x else 'Video')

    extracted_count = 0
    for _, row in labels_df.iterrows():
        segment = extract_segment(hrv_df, row['start_time'], row['end_time'], row['File_name'])
        if not segment.empty:
            segment['participant'] = pid
            segment['Q1'] = row.get('Q1', np.nan)
            segment['Q2'] = row.get('Q2', np.nan)
            segment['Q3'] = row.get('Q3', np.nan)
            segment['Q4'] = row.get('Q4', np.nan)
            segment['Emotion'] = row.get('Emotion', np.nan)
            segment['type'] = row['type']
            all_segments.append(segment)
            extracted_count += len(segment)

# Combine all participants' segments
combined_df = pd.concat(all_segments, ignore_index=True)

combined_df = pd.concat(all_segments, ignore_index=True)
print(f"\nFinal combined dataset shape: {combined_df.shape}")

# --- 5. Prepare Final Dataset for Modeling ---

# Aggregate Mean HRV across each clip per participant
final_df = combined_df.groupby(['participant', 'type', 'Q1', 'Q2', 'Q3', 'Q4', 'Emotion']).agg(
    mean_hrv=('prv_rmssd_ms', 'mean')
).reset_index()

# Map emotion labels
emotion_labels = {0: 'Relaxed', 1: 'Happy', 2: 'Sad', 3: 'Neutral', 4: 'Angry'}
final_df['emotion_name'] = final_df['Emotion'].map(emotion_labels)

# Separate audio and video
audio_data = final_df[final_df['type'] == 'Audio']
video_data = final_df[final_df['type'] == 'Video']

print("\nğŸ” Checking shapes:")
print(f"audio_data shape: {audio_data.shape}")
print(f"video_data shape: {video_data.shape}")

print("\nğŸ” Audio Data - Missing Summary:")
print(audio_data[['mean_hrv', 'Emotion']].isnull().sum())

print("\nğŸ” Video Data - Missing Summary:")
print(video_data[['mean_hrv', 'Emotion']].isnull().sum())

print("\nğŸ” Audio Data - Sample Rows:")
print(audio_data[['mean_hrv', 'Emotion']].head())

print("\nğŸ” Video Data - Sample Rows:")
print(video_data[['mean_hrv', 'Emotion']].head())

def plot_hrv_distribution(df, title):
    # Drop rows with missing HRV or missing emotion_name
    df = df.dropna(subset=['mean_hrv', 'Emotion'])

    if df.empty:
        print(f"âš ï¸ No valid data available for {title}. Skipping plot.")
        return

    plt.figure(figsize=(8,6))
    sns.boxplot(x='Emotion', y='mean_hrv', data=df)
    plt.ylim(0, df['mean_hrv'].max() * 1.1)
    plt.title(f'HRV Distribution by Emotion - {title}')
    plt.xlabel('Emotion')
    plt.ylabel('Mean HRV (ms)')
    plt.grid(True)
    plt.show()



print("\nğŸ“Š Plotting Audio HRV Distribution")
plot_hrv_distribution(audio_data, 'Audio Clips')

print("\nğŸ“Š Plotting Video HRV Distribution")
plot_hrv_distribution(video_data, 'Video Clips')

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Features to use
features = ['mean_hrv', 'Q1', 'Q2', 'Q3', 'Q4']

# Prepare Audio dataset
X_audio = audio_data[features]
y_audio = audio_data['Emotion']

# Prepare Video dataset
X_video = video_data[features]
y_video = video_data['Emotion']

# Prepare Combined dataset
X_combined = pd.concat([audio_data, video_data])
X_combined_features = X_combined[features]
y_combined = X_combined['Emotion']

def train_random_forest(X, y, title):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\\nğŸ”µ {title} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    return model

# Train models
rf_audio = train_random_forest(X_audio, y_audio, "Audio Clips Model")
rf_video = train_random_forest(X_video, y_video, "Video Clips Model")
rf_combined = train_random_forest(X_combined_features, y_combined, "Combined Audio+Video Model")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def plot_confusion_matrix(model, X_test, y_test, title):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    disp.plot(cmap='Blues', xticks_rotation=45)
    plt.title(title)
    plt.grid(False)
    plt.show()

# Redefine train_random_forest to return (model, X_test, y_test)
def train_random_forest(X, y, title):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\\nğŸ”µ {title} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    return model, X_test, y_test

# Train again and capture model + data
rf_audio_model, X_audio_test, y_audio_test = train_random_forest(X_audio, y_audio, "Audio Clips Model")
rf_video_model, X_video_test, y_video_test = train_random_forest(X_video, y_video, "Video Clips Model")
rf_combined_model, X_combined_test, y_combined_test = train_random_forest(X_combined_features, y_combined, "Combined Audio+Video Model")

# Plot confusion matrices
plot_confusion_matrix(rf_audio_model, X_audio_test, y_audio_test, "Confusion Matrix - Audio Clips")
plot_confusion_matrix(rf_video_model, X_video_test, y_video_test, "Confusion Matrix - Video Clips")
plot_confusion_matrix(rf_combined_model, X_combined_test, y_combined_test, "Confusion Matrix - Combined Clips")

import numpy as np
import matplotlib.pyplot as plt

def plot_feature_importance(model, feature_names, title):
    importances = model.feature_importances_
    indices = np.argsort(importances)

    plt.figure(figsize=(8,6))
    plt.title(f"Feature Importances - {title}")
    plt.barh(range(len(indices)), importances[indices], align='center')
    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
    plt.xlabel('Relative Importance')
    plt.grid(True)
    plt.show()

# Run for all models
plot_feature_importance(rf_audio_model, ['mean_hrv', 'Q1', 'Q2', 'Q3', 'Q4'], "Audio Model")
plot_feature_importance(rf_video_model, ['mean_hrv', 'Q1', 'Q2', 'Q3', 'Q4'], "Video Model")
plot_feature_importance(rf_combined_model, ['mean_hrv', 'Q1', 'Q2', 'Q3', 'Q4'], "Combined Model")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def plot_confusion_matrix(model, X_test, y_test, title):
    y_pred = model.predict(X_test)
    labels = sorted(list(set(y_test)))
    cm = confusion_matrix(y_test, y_pred, labels=labels)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    disp.plot(cmap='Blues', xticks_rotation=45)
    plt.title(title)
    plt.grid(False)
    plt.show()

# Retrain and capture test sets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

def train_rf(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    clf = RandomForestClassifier(random_state=42)
    clf.fit(X_train, y_train)
    return clf, X_test, y_test

rf_audio_model, X_audio_test, y_audio_test = train_rf(X_audio, y_audio)
rf_video_model, X_video_test, y_video_test = train_rf(X_video, y_video)
rf_combined_model, X_combined_test, y_combined_test = train_rf(X_combined_features, y_combined)

# Plot confusion matrices
plot_confusion_matrix(rf_audio_model, X_audio_test, y_audio_test, "Confusion Matrix - Audio")
plot_confusion_matrix(rf_video_model, X_video_test, y_video_test, "Confusion Matrix - Video")
plot_confusion_matrix(rf_combined_model, X_combined_test, y_combined_test, "Confusion Matrix - Combined")

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Drop missing emotion rows
ml_df = combined_df.dropna(subset=['Emotion'])

# Encode emotion as label
ml_df['Emotion_Label'] = ml_df['Emotion'].astype('category').cat.codes

X = ml_df[['prv_rmssd_ms', 'Q1', 'Q2', 'Q3', 'Q4']]
y = ml_df['Emotion_Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("ğŸ¯ Emotion Classification Report:")
print(classification_report(y_test, y_pred))